{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "GloVe Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygBHZ2O-MFK1",
        "colab_type": "text"
      },
      "source": [
        "# Analyse des ressentis avec GloVe Vectors\n",
        "\n",
        "L'analyse des ressentis a pour objectif de classifier les opinions exprimées sous forme de texte dans un langage naturel. Différentes méthodes peuvent être utlisées pour réaliser cette analyse. Dans cet exemple, des commentaires recueillis surle site [allociné](http://www.allocine.fr/) vont être utlisés pour entrainer un modèle de classification supervisé. Le modèle utilise un réseau de neurones à convolution 1D.\n",
        "\n",
        "Les mots contenus dans les phrases doivent être encodés dans des vecteurs qui seront utilisés pour l'entrainement et les tests. Une manière simple serait d'assigner à chaque mot une valeur numérique. Le problème de cette méthode est que le contexte dans lequel les mots sont utilisés n'est pas pris en compte. Une méthode permettant de combler ce manque est d'utiliser un algorithme de prolongation lexicale (Word embedding). Parmi ce genre d'algorithme, on trouve [GloVe (Global Vectors for Word Representation)](https://nlp.stanford.edu/projects/glove/) qui se base sur les probabilités de co-occurence de mots. Une base de données pré-entrainée (mais en Anglais) est déjà disponnible sur leur site web.  \n",
        "\n",
        "Une base de donnée pré-entrainée en Français peut-être néanmoins téléchargée à cette [adresse](http://www.cs.cmu.edu/~afm/projects/multilingual_embeddings.html). C'est celle-ci que nous utiliserons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVAIpfO0MFK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN_eQNboMFLA",
        "colab_type": "text"
      },
      "source": [
        "# Chargement des données d'entrainement\n",
        "\n",
        "Les données d'entrainement sont chargées dans une dataframe Panda depuis des fichiers textes. Ces données contiennent deux colonnes : Un commentaire et une valeur binaire définissant un sentiment négatif ou positif sur ce commentaire. \n",
        "\n",
        "Ces données sont disponnibles sur le github de [TheophileBlard](https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/tree/master/allocine_dataset). Ces données sont issues de commentaires récupérés sur Allociné. Les utilisateurs votent avec des notes allant de 0.5 à 5.0 :    \n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/rating_counts.png?raw=1\" width=\"600\"/>\n",
        "\n",
        "Afin de récupérer une note binaire (négative ou positive) à partir de cet intervalle de valeurs, les votes <= 2 sont classé comme négatifs et ceux >=4 sont classés comme positifs. Les autres sont classés comme neutres :    \n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/polarity_frequency.png?raw=1\" width=\"600\"/>  \n",
        "  \n",
        "\n",
        "Enfin, pour construire les données, 100 000 avis négatifs et 100 000 avis positifs sont extraits aléatoirement, puis décomposés en deux catégories : Les données d'entrainement (80%), les données de test (10%) et les données de validation (10%) :  \n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/splits_polarity.png?raw=1\" width=\"600\"/>  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFyrqXX4M5ek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "b6f5efce-da69-4e85-ed3e-ea1bc907e6b8"
      },
      "source": [
        "# Téléchargement des données depuis le repot github \"https://github.com/AlexandreBourrieau/ML-F1/raw/master/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\"\n",
        "\n",
        "!wget \"https://github.com/AlexandreBourrieau/ML-F1/raw/master/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\"\n",
        "!tar -xjvf data.tar.bz2\n",
        "!ls -l data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-13 16:39:23--  https://github.com/AlexandreBourrieau/ML-F1/raw/master/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/AlexandreBourrieau/ML-F1/master/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2 [following]\n",
            "--2020-09-13 16:39:24--  https://raw.githubusercontent.com/AlexandreBourrieau/ML-F1/master/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66625305 (64M) [application/octet-stream]\n",
            "Saving to: ‘data.tar.bz2’\n",
            "\n",
            "data.tar.bz2        100%[===================>]  63.54M  67.1MB/s    in 0.9s    \n",
            "\n",
            "2020-09-13 16:39:28 (67.1 MB/s) - ‘data.tar.bz2’ saved [66625305/66625305]\n",
            "\n",
            "data/\n",
            "data/allocine_dataset.pickle\n",
            "data/test.jsonl\n",
            "data/train.jsonl\n",
            "data/val.jsonl\n",
            "total 247576\n",
            "-rw-r--r-- 1 1000 1000 119034075 Feb  6  2020 allocine_dataset.pickle\n",
            "-rw-r--r-- 1 1000 1000  13554101 Feb  6  2020 test.jsonl\n",
            "-rw-r--r-- 1 1000 1000 107365432 Feb  6  2020 train.jsonl\n",
            "-rw-r--r-- 1 1000 1000  13550874 Feb  6  2020 val.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je5Lkv_aMFLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "76226819-42fd-4acd-b391-48486110b102"
      },
      "source": [
        "DataEntrainement = pd.read_json(\"/content/data/test.jsonl\", lines=True)\n",
        "DataEntrainement.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>film-url</th>\n",
              "      <th>review</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-25385/cr...</td>\n",
              "      <td>Magnifique épopée, une belle histoire, touchan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-1954/cri...</td>\n",
              "      <td>Je n'ai pas aimé mais pourtant je lui mets 2 é...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-135523/c...</td>\n",
              "      <td>Un dessin animé qui brille par sa féerie et se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-61514/cr...</td>\n",
              "      <td>Si c'est là le renouveau du cinéma français, c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-260395/c...</td>\n",
              "      <td>Et pourtant on s’en Doutait !Second volet très...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-220641/c...</td>\n",
              "      <td>Vous reprendrez bien un peu d'été ? Ce film je...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-120103/c...</td>\n",
              "      <td>Bon c'est pas un grand film mais on passe un b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-190956/c...</td>\n",
              "      <td>Terrible histoire que ces êtres sans amour, ce...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-186185/c...</td>\n",
              "      <td>Un très joli film, qui ressemble à un téléfilm...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-17327/cr...</td>\n",
              "      <td>Mais comment certaines personnes ont pus lui m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            film-url  ... polarity\n",
              "0  http://www.allocine.fr/film/fichefilm-25385/cr...  ...        1\n",
              "1  http://www.allocine.fr/film/fichefilm-1954/cri...  ...        0\n",
              "2  http://www.allocine.fr/film/fichefilm-135523/c...  ...        1\n",
              "3  http://www.allocine.fr/film/fichefilm-61514/cr...  ...        0\n",
              "4  http://www.allocine.fr/film/fichefilm-260395/c...  ...        0\n",
              "5  http://www.allocine.fr/film/fichefilm-220641/c...  ...        1\n",
              "6  http://www.allocine.fr/film/fichefilm-120103/c...  ...        1\n",
              "7  http://www.allocine.fr/film/fichefilm-190956/c...  ...        1\n",
              "8  http://www.allocine.fr/film/fichefilm-186185/c...  ...        1\n",
              "9  http://www.allocine.fr/film/fichefilm-17327/cr...  ...        0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq6cMhkEMFLG",
        "colab_type": "text"
      },
      "source": [
        "# Chargement des vecteurs GloVe et préparation des données\n",
        "\n",
        "**Commençons par charger les vecteurs GloVe**  \n",
        "\n",
        "Les fichiers des vecteurs GloVe sont téléchargés à partir du site de [GloVe](https://nlp.stanford.edu/projects/glove/) mais ils sont en Anglais. Nous allons utiliser une [version française](http://www.cs.cmu.edu/~afm/projects/multilingual_embeddings.html) équivalente.  \n",
        "  \n",
        "Le fichier que nous utilisons contient plus de 40000 vecteurs de dimension 300. Cela signifie que pour chaque mot contenu dans ce fichier, un vecteur de 300 valeurs permet de définir les relations lexicales de ce mots avec les autres mots du fichier.  \n",
        "\n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/EmbeddedVectors.png?raw=1\"/>  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGcwMGR-R3tR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "f9537035-3192-40b3-c7d2-b1bddf7e42aa"
      },
      "source": [
        "# Téléchargement des vecteurs\n",
        "!wget \"https://github.com/AlexandreBourrieau/ML-F1/raw/master/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar\"\n",
        "!mv multilingual_embeddings.rar /content/data/multilingual_embeddings.rar\n",
        "!unrar x /content/data/multilingual_embeddings.rar /content/data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-13 16:39:55--  https://github.com/AlexandreBourrieau/ML-F1/raw/master/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/AlexandreBourrieau/ML-F1/master/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar [following]\n",
            "--2020-09-13 16:39:56--  https://raw.githubusercontent.com/AlexandreBourrieau/ML-F1/master/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80894821 (77M) [application/octet-stream]\n",
            "Saving to: ‘multilingual_embeddings.rar’\n",
            "\n",
            "multilingual_embedd 100%[===================>]  77.15M  71.9MB/s    in 1.1s    \n",
            "\n",
            "2020-09-13 16:40:01 (71.9 MB/s) - ‘multilingual_embeddings.rar’ saved [80894821/80894821]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/data/multilingual_embeddings.rar\n",
            "\n",
            "Extracting  /content/data/multilingual_embeddings.fr                     \b\b\b\b  5%\b\b\b\b 10%\b\b\b\b 15%\b\b\b\b 20%\b\b\b\b 25%\b\b\b\b 31%\b\b\b\b 36%\b\b\b\b 41%\b\b\b\b 46%\b\b\b\b 51%\b\b\b\b 57%\b\b\b\b 62%\b\b\b\b 67%\b\b\b\b 72%\b\b\b\b 77%\b\b\b\b 82%\b\b\b\b 88%\b\b\b\b 93%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNI60PfJkhp8",
        "colab_type": "text"
      },
      "source": [
        "**Encodage des commentaires**  \n",
        "Pour utiliser notre réseau de neurones, nous devons encoder le texte des commentaires. L'encodage suit le principe suivant :  \n",
        "* Chaque mot contenu dans l'ensemble des commentaires va se voir attribuer une valeur entière unique\n",
        "* Chaque commentaire va ensuite être transformé en un vecteur de nombre entiers, dont les nombres correspondent aux valeurs entières attribuées aux mots précédemment  \n",
        "* Les commentaires sont ensuite redimensionnés afin d'avoir tous la même dimension (avec bourrage de 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MobDmxmfzg69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ceb5a6ba-ac43-42db-d046-e65a36187805"
      },
      "source": [
        "print(DataEntrainement['review'][0])\n",
        "print(DataEntrainement['review'][1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Magnifique épopée, une belle histoire, touchante avec des acteurs qui interprètent très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), le genre de film qui se savoure en famille! :)\n",
            "Je n'ai pas aimé mais pourtant je lui mets 2 étoiles car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGcJIZiQk8t5",
        "colab_type": "text"
      },
      "source": [
        "Voici un exemple d'encodage de texte :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UapGqFb6lAx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "48421462-a6f2-45c0-bb9c-91902926fee6"
      },
      "source": [
        "com = ['un plus un egal deux','deux plus deux cela fait quatre']\n",
        "tokenizer_ex = Tokenizer(num_words=10)\n",
        "tokenizer_ex.fit_on_texts(com)\n",
        "seq = tokenizer_ex.texts_to_sequences(com)\n",
        "bourrage = pad_sequences(seq,maxlen=10)\n",
        "\n",
        "print(com)\n",
        "print(tokenizer_ex.word_index)\n",
        "print(seq)\n",
        "print(bourrage)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['un plus un egal deux', 'deux plus deux cela fait quatre']\n",
            "{'deux': 1, 'un': 2, 'plus': 3, 'egal': 4, 'cela': 5, 'fait': 6, 'quatre': 7}\n",
            "[[2, 3, 2, 4, 1], [1, 3, 1, 5, 6, 7]]\n",
            "[[0 0 0 0 0 2 3 2 4 1]\n",
            " [0 0 0 0 1 3 1 5 6 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvcLUToHlN2N",
        "colab_type": "text"
      },
      "source": [
        "Le code suivant réalise ces opérations avec les données d'entrainements de notre projet :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqI5FJ8OlRWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_MOTS = 1000000\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "\n",
        "# Chargement des commentaires et des ressentis\n",
        "commentaires = DataEntrainement['review'].astype(str).tolist()      # Récupère tous les commentaires dans une liste python\n",
        "ressentis = DataEntrainement['polarity'].tolist()                   # Récupère tous les ressentis dans une liste python\n",
        "labels = np.asarray(ressentis)                                      # Créé un tableau de type numpy avec les ressentis\n",
        "\n",
        "# Encodage des commentaires\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_MOTS)                              # Initialise la fonction Tokenizer de Keras\n",
        "tokenizer.fit_on_texts(commentaires)                                      # Création des index des mots\n",
        "sequences = tokenizer.texts_to_sequences(commentaires)                    # Transformation des phrases en séquences d'index de mots \n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)   # Bourrage des vecteurs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCHB2BuP2vH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "43f055ff-2dc6-475c-8799-618597a97186"
      },
      "source": [
        "padded_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ..., 10022,    11,   264],\n",
              "       [    0,     0,     0, ...,    65,     5,   645],\n",
              "       [    0,     0,     0, ...,     2,    59,   840],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,    21,  1142,   205],\n",
              "       [    0,     0,     0, ...,  6098,    19,    81],\n",
              "       [    0,     0,     0, ...,    62,    37,  1191]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ycKyMN296u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvHU4F21lWHh",
        "colab_type": "text"
      },
      "source": [
        "**Création des données d'entrainement et de tests**  \n",
        "On utilise la fonction `train_test_split` de [ScikitLearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) afin de créer les données d'entrainement et de tests à partir des séquences :\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBFoHU9RlkOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_des_mots = tokenizer.word_index\n",
        "nbr_mots = min(MAX_NB_MOTS, len(index_des_mots)) + 1\n",
        "\n",
        "x_entrainement, x_test, y_entrainement, y_test = train_test_split(padded_sequences, labels, test_size=0.2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg3t3ahhxJ9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "561457c3-189f-4f50-ad2a-fce45306102a"
      },
      "source": [
        "y_entrainement"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdcJUpqilsoC",
        "colab_type": "text"
      },
      "source": [
        "**Création de la matrice embarquant les données numériques des vecteurs des mots contenus dans les commentaires**  \n",
        "L'objectif est ici de créer une matrice dont chaque ligne contient le vecteur du mot issu de l'algorithme GolVe. La matrice est donc de taille n x m avec :  \n",
        "* n : Nombre de mots (uniques) pris en compte dans l'ensemble des commentiares  \n",
        "* m : Nombre de valeurs contenues dans les vecteurs GolvE (300 dans notre exemple)  \n",
        "  \n",
        "$$\\begin{array}{*{20}{c}}\n",
        "{glace}\\\\\n",
        "{soda}\\\\\n",
        "{...}\\\\\n",
        "{film}\n",
        "\\end{array}\\left( \\begin{array}{l}\n",
        "\\begin{array}{*{20}{c}}\n",
        "{ - 0.3}&{0.2}&{...}&{0.32}&{ - 0.24}\n",
        "\\end{array}\\\\\n",
        "\\begin{array}{*{20}{c}}\n",
        "{ - 0.1}&{0.3}&{...}&{0.52}&{ - 0.94}\n",
        "\\end{array}\\\\\n",
        "\\begin{array}{*{20}{c}}\n",
        "{...}&{...}&{...}&{...}&{...}\n",
        "\\end{array}\\\\\n",
        "\\begin{array}{*{20}{c}}\n",
        "{ - 0.5}&{0.9}&{...}&{0.72}&{ - 0.24}\n",
        "\\end{array}\n",
        "\\end{array} \\right)$$    \n",
        "  \n",
        "    \n",
        "\n",
        "Les lignes ne sont pas arrangées dans n'importe quel ordre : Elles suivent l'ordre des séquences créées par la fonction `tokenizer.texts_to_sequences()`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp7oQXgtVz8x",
        "colab_type": "text"
      },
      "source": [
        "Pour cela définit tout d'abord la fonction `Chargement_Vecteurs()` qui va créer un tableau de type numpy, avec pour chaque mot son vecteur correspondant :  \n",
        "\n",
        "\n",
        "```\n",
        "  ...\n",
        "  'embêtant': array([-2.26152748e-01,  3.20324749e-01, -1.10406213e-01, -6.05279326e-01,\n",
        "        -4.68072683e-01,  1.29561171e-01,  5.62916815e-01, -1.16834176e+00,\n",
        "       ...\n",
        "        -7.50736117e-01, -2.48611599e-01, -2.42264550e-02, -9.54209745e-01],\n",
        "       dtype=float32),\n",
        " 'lockheed': array([ 3.6074609e-01, -8.0667698e-01,  8.7549436e-01,  6.2351477e-01,\n",
        "        -9.2155904e-01,  7.3180795e-01, -2.8121206e-01,  2.9078028e-01,\n",
        "        ...\n",
        "         1.5100185e+00,  8.1941241e-01, -1.6970781e+00,  1.9289741e-01],\n",
        "       dtype=float32),\n",
        " 'séparez': array([-0.5703459 , -0.8884122 , -0.4579496 ,  0.55588883, -0.8727098 ,\n",
        "         0.56783265, -0.10067926,  0.14027229, -0.89301944, -0.42706665,\n",
        "        ...\n",
        "        -0.36254016, -0.40695533,  1.087127  , -0.641696  ,  0.10919298,\n",
        "        ...\n",
        "```  \n",
        "\n",
        "Puis la fonction `Creation_Matrice()` qui va créer notre matrice. Pour chaque mot contenu dans les séquences créées par la fonction `tokenizer.texts_to_sequences` on récupère le vecteur correspondant à l'aide du tableau numpy créé précédemment. Ainsi chaque ligne de la matrice indexe chaque mot des séquences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVeUb4AsMFLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_VECTORS = 400000\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "def Chargement_Vecteurs():\n",
        "    print('Chargement des vecteurs GloVe...')\n",
        "    glove_dict = {}\n",
        "    Max_Nb_Vect = 0\n",
        "    with open('/content/data/multilingual_embeddings.fr', encoding='utf8') as fichier:\n",
        "        for ligne in fichier:\n",
        "            Max_Nb_Vect = Max_Nb_Vect + 1\n",
        "            if Max_Nb_Vect > MAX_NB_VECTORS:\n",
        "              break\n",
        "            valeur = ligne.split()\n",
        "            mot = valeur[0]\n",
        "            glove_dict[mot] = np.asarray(valeur[1:], dtype='float32')\n",
        "    return glove_dict\n",
        "\n",
        "def Creation_Matrice(index_mot, nbr_mots):\n",
        "    glove_dict = Chargement_Vecteurs()\n",
        "    matrice = np.zeros((nbr_mots, EMBEDDING_DIM))\n",
        "    for mot, i in index_mot.items():\n",
        "        if i > nbr_mots:\n",
        "            continue\n",
        "        vector = glove_dict.get(mot)\n",
        "        if vector is not None:\n",
        "            matrice[i] = vector\n",
        "    print('Matrice créée...')\n",
        "    return matrice"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKg1xxG1t7rQ",
        "colab_type": "text"
      },
      "source": [
        "Regardons à quoi cela ressemble sur notre précédent exemple :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocbWFigsU7I5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "99fde6eb-2612-4b17-9902-80a6de9c76a8"
      },
      "source": [
        "print(com)\n",
        "print(tokenizer_ex.word_index)\n",
        "\n",
        "matrice = Creation_Matrice(tokenizer_ex.word_index, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['un plus un egal deux', 'deux plus deux cela fait quatre']\n",
            "{'deux': 1, 'un': 2, 'plus': 3, 'egal': 4, 'cela': 5, 'fait': 6, 'quatre': 7}\n",
            "Chargement des vecteurs GloVe...\n",
            "Matrice créée...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiyyluWRvSEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "dfe45a68-e095-4ffc-f73f-879f09a5e16f"
      },
      "source": [
        "matrice"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.14380729, -0.15245135, -0.32095706, ..., -0.2833837 ,\n",
              "         0.20184219, -0.3477053 ],\n",
              "       [ 0.02684828,  0.34394601, -0.17763138, ..., -0.31729311,\n",
              "        -0.08849339,  0.17732655],\n",
              "       ...,\n",
              "       [ 0.38667157, -0.01152001, -0.22971489, ..., -0.3842952 ,\n",
              "         0.18768422, -0.45241103],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQJoxfCTf1Hd",
        "colab_type": "text"
      },
      "source": [
        "On créé donc maintenant la matrice pour notre projet :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZlja3d1MFLL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "23631567-ab80-401d-bad1-96bbfffd1ef4"
      },
      "source": [
        "matrice = Creation_Matrice(index_des_mots, nbr_mots)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chargement des vecteurs GloVe...\n",
            "Matrice créée...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mnxIJKC5wPO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d03F2eT2gbYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25a14a66-b889-4c9a-db3e-3c5bfdede95f"
      },
      "source": [
        "matrice.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66079, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSCKoWPYMFLN",
        "colab_type": "text"
      },
      "source": [
        "# Définition du Modèle\n",
        "\n",
        "Nous utilisons un réseau de neurones à convolution 1D avec Keras et en utilisant la matrice créée précédemment afin de paramétrer la couche interne. La couche interne est pré-entrainée donc nous n'avons pas d'entrainement à réaliser sur celle-ci.  \n",
        "\n",
        "La structure du réseau est la suivante :  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9G1oAXnVJJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "outputId": "95de97f9-a8d4-4430-c25e-7df6bb9835bd"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/Conv1D2.png?raw=1', width=1500)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/Conv1D2.png?raw=1\" width=\"1500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0IUw1VDMFLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "1f0b86f2-5c42-4a1a-aecf-edb0814011e1"
      },
      "source": [
        "dropout = 0.4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(nbr_mots, EMBEDDING_DIM, weights=[matrice],\n",
        "                    input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Conv1D(128, 5, activation='relu', padding='same', strides=2))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1000, 300)         19823700  \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1000, 300)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 500, 128)          192128    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 20,032,598\n",
            "Trainable params: 208,898\n",
            "Non-trainable params: 19,823,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWFUoRi6XZYU",
        "colab_type": "text"
      },
      "source": [
        "# Entrainement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUMaXNjMMFLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['acc'])\n",
        "\n",
        "# Entraine le modèle sur un certain nombre d'itérations\n",
        "historique = model.fit(x_entrainement, y_entrainement, batch_size=128, epochs=40, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evalue le modèle avec les échantillons de tests\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Fonction d\\'objectif des tests :', score[0])\n",
        "print('Précision des tests :', score[1])\n",
        "\n",
        "# Synthèse\n",
        "plt.plot(historique.history['acc'])\n",
        "plt.plot(historique.history['val_acc'])\n",
        "plt.title('Précision du modèle')\n",
        "plt.ylabel('Précision')\n",
        "plt.xlabel('Itérations')\n",
        "plt.legend(['Entrainements', 'Tests'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LVwi0vLMFLS",
        "colab_type": "text"
      },
      "source": [
        "# Prédictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i423WNQMFLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(padded_sequences)\n",
        "most_likely = predictions.argmax(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ve2a-roMFLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = random.randrange(len(predictions))\n",
        "print(comments[index])\n",
        "print('Prediction: %d, label: %d' % (most_likely[index], sentiments[index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcR3Qu6FMFLX",
        "colab_type": "text"
      },
      "source": [
        "# Analyse des erreurs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7aMVD5lMFLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "fb06e115-3f3d-4491-837a-673e648f3750"
      },
      "source": [
        "for i in range(10000):\n",
        "    index = random.randrange(len(predictions))\n",
        "    if most_likely[index] != sentiments[index]:\n",
        "        break\n",
        "\n",
        "print(comments[index])\n",
        "print('Prediction: %d, label: %d' % (most_likely[index], sentiments[index]))\n",
        "\n",
        "plt.bar(range(num_classes), predictions[index], tick_label=range(num_classes))\n",
        "plt.title('Prediction values')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You get extra minutes so that you can carry out the call and not get cut off.\"\n",
            "Prediction: 0, label: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+H89ldVkgGukjwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMplVIcbMFLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}